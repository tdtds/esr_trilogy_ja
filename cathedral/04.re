= はやめのリリース、しょっちゅうリリース

　はやめにしょっちゅうリリースするのは、Linux開発モデルの重要な部分だ。ほとんどの開発者（含ぼく）は、プロジェクトがちょっとでも大きくなったらこいつはまずいやり方だと考えていた。初期バージョンはその定義からいってバグだらけだし、ユーザの我慢にも限度があるだろうから。

　この信念のおかげで、伽藍建設式の開発への関与も深まった。もし最優先課題が、できるだけ少ないバグしかユーザにお目にかけないということだったら、うん、それならリリースは半年に一度とかにして（あるいはもっと間をおいて）、リリースの間は犬みたいにひたすらバグ取りに専念するだろう。Emacsの C の核部分はこういう形で開発された。Lisp ライブラリは、事実上ちがっていた。FSFのコントロールのきかない活発なLispアーカイブがあって、そこにいけば Emacsのリリースサイクルとはまったく関係ない、新しい開発コードが手に入ったから@<fn>{QR}。

　こういうアーカイブのいちばん重要なものの一つは、オハイオ州立大の elisp アーカイブでここは今日の大きな Linuxアーカイブの精神や特徴の多くを先取りしたところだった。でも、自分たちがなにをしているのかしっかり考えてみた者はほとんどいなかったし、このアーカイブの存在自体が、FSF 式の伽藍建設型開発モデルの問題点についてなにを示唆しているのかについてもあまり考えなかった。1992年頃、ぼくはオハイオのコードの相当部分を正式に公式 Emacs Lispライブラリに組み込もうとして、かなりまじめに取り組んだ。でも政治的な問題にぶちあたって、ほとんどうまくいかなかった。

　でもそれから一年たたないうちに、Linux がかなり目に見えて広まってくると、なにかちがった、ずっと健全なことが起こっているのははっきりしてきた。リーヌスのオープンな開発方針は、伽藍建設の正反対のものだった。Sunsite （現@<href>{http://metalab.unc.edu/, metalab}）や tsx-11 のアーカイブははちきれそうで、パッケージもどんどん登場してきた。そしてそのすべてが、前代未聞の頻度でリリースされるコアシステムに動かされていた。

　リーヌスはいちばん効果的なやりかたで、ユーザたちを共同開発者として扱っていたことになる：

//footnote[QR][インターネットに先立つ、成功したオープンソースのバザール形式開発で、しかも Unix やインターネットの伝統とは関係ないものも存在している。1990-92 年の@<href>{http://www.cdrom.com/pub/infozip/, info-Zip 圧縮ユーティリティ}の開発（主に DOS マシン用）はその一例だ。もう一つあるのが、RBBS BBS ソフトだ（これまた DOS 用）。これは 1983年に始まって、なかなか強力なコミュニティが形成され、インターネットの電子メールやファイル共有のほうがローカルの BBSよりもずっと技術的なメリットが高くなった今（ 1999 年半ば）にいたるまで、定期的なリリースを繰り返している。info-ZIPコミュニティはある程度までインターネットの電子メールに頼っていたけれど、RBBS 開発者の文化は、RBBS自身を使って相当なオンラインコミュニティを擁し、完全に TCP/IP インフラとは独立していた。]

7. はやめのリリース、ひんぱんなリリース。そして顧客の話をきくこと

　リーヌスの革新は、これをやったということじゃない（似たようなことは、もうながいこと Unixの世界の伝統になっていた）。それをスケールアップして、開発しているものの複雑さに見合うだけの集中した取り組みにまでもっていったということだった。開発初期のあの頃だと、リーヌスが新しいカーネルを@<strong>{一日に}何回もリリースすることだって、そんなに珍しくはなかった。そしてかれは、共同開発者の基盤をうまく育てて、インターネットでうまく共同作業をする点で、ほかのだれよりも上をいっていた。それでうまくいったわけだ。

　でも、@<strong>{具体的にどういうふうに}うまくいってるんだろう。そしてそれはぼくでもまねできるものなんだろうか、それとも リーヌスだけにしかない独特な才能に依存したものなんだろうか？　そうは思えなかった。そりゃもちろん、リーヌスはまったく大したハッカーだ（完全な製品レベルの OSカーネルをつくりあげられる人間が、ぼくたちのなかでどれだけいるね？）。でも、Linuxはとんでもないソフトウェア思想上の進歩を取り込んだりはしていない。リーヌスは、たとえばリチャード・ストールマンとかジェームズ・ゴスリング（NeWSとJavaで有名）のような、設計面での革新的天才ではないんだ（少なくともいまのところは）。むしろリーヌスはエンジニアリングの天才なんじゃないかと思う。バグや開発上の袋小路を避ける第六感と、A 地点から B地点にたどりつく、いちばん楽な道を見つけだす真の直感もある。Linuxの設計はすべて、この特徴が息づいているし、リーヌスの本質的に地道で単純化するような設計アプローチが反映されている。

　じゃあ、もし急速リリースと、インターネットの徹底的な使い倒しが偶然ではなくて、労力を最小限ですまそうとするリーヌスのエンジニアリング上の天才的洞察の不可欠な部分だったんなら、かれが最大化しているのは何だったんだろう。この仕組みからかれがひねりだしているのはなんだったんだろう。

　こういう問題のたてかたをすれば、質問自体が答になる。リーヌスは、ハッカー/ユーザたちをたえず刺激して、ごほうびを与え続けたってことだ。刺激は、全体の動きの中で一員となることでエゴを満足させられるという見込みで、ごほうびは、自分たちの仕事がたえず（まさに@<strong>{毎日のように}）進歩している様子だ。

　リーヌスは、デバッグと開発に投入される人・時間を最大化することをずばり狙っていたわけだ。コードの安定性が犠牲になったり、なにか深刻なバグがどうしようもなくなったら、ユーザ基盤に見放されるかもしれないという危険をおかしてまでそれをやっていた。リーヌスの行動を見ていると、次のような信念を持っていたんじゃないかと思える：

8. ベータテスタと共同開発者の基盤さえ十分大きければ、ほとんどすべての問題はすぐに見つけだされて、その直し方もだれかにはすぐわかるはず。

　あるいはもっとくだけた表現だと、「目玉の数さえ十分あれば、どんなバグも深刻ではない」。これをぼくはリーヌスの法則と呼んでる。

　はじめにこの法則を書いたときは、どんな問題も「だれかには明白だ」という書き方をしていた。リーヌスはこれに異議を唱えて、問題を理解してそれをなおす人物は、必ずしもどころかふつうは、その問題を最初に記述する人間ではないと言った。「だれかが問題を見つける。そしてそれを理解するのはだれか@<strong>{別の人}だよ。そして問題を見つけることのほうがむずかしいとぼくが述べたことは記録しておいてね」。でも肝心なのは、見つけるのもなおすのも、だいたいすごく短期間で起きるってことだ。

　ここに、伽藍建築方式とバザール式のちがいの核心部分があるんだと思う。伽藍建設者的なプログラミングの見方では、バグや開発上の問題はややこしく、潜伏した深い現象だ。問題を全部ほじくりだしたと確信できるようになるには、少数の人が何ヶ月も専念してチェックしなきゃならない。だからリリースの間隔も開いてくるし、長く待たされたリリースが完璧じゃないときには、どうしても失望も大きくなる。

　一方のバザール的見方だと、バグなんてほとんどは深刻な現象じゃないという前提にたつことになる――少なくとも、リリースを一つ残らず、千人の熱心な共同開発者が叩いてくれるような状況にさらされたら、どんなバグも早々に浮上してくると考える。よって、たくさんなおしてもらうためにリリースも増やすし、有益な副作用としては、ときどきヘマが出回っちゃっても、あんまり失うものは大きくないってわけ。

　そして、これがすべてだ。これだけで必要十分。もしリーヌスの法則がまちがってるなら、Linux カーネルほど複雑なシステム、Linuxカーネルくらいみんながよってたかってハッキングしてるようなシステムは、どこかの時点でまずい相互作用や、発見できない「深い」バグのせいで崩壊してたはずなんだ。一方、もしリーヌスの法則が正しければ、これで Linux が相対的にバグが少ないことを十分説明できる。

　そしてこれは、そんなに驚くべきことでもなかったのかもしれない。社会学者たちは何年も前に、同じくらいの専門家（あるいは同じくらい無知な人たち）の意見の平均は、そういう観察者の一人をランダムに選んで意見をきくよりも、予測精度がかなり高いことを発見している。これをかれらは「デルファイ効果」と呼んだ。どうやらリーヌスが示したのは、これが OS のデバッグにも適用できるってことみたいだ。つまりデルファイ効果は、OSカーネル級の複雑なものでも、開発上の複雑さをおさめることができるんだ。

　Linuxの場合の特別な性格で、デルファイ効果的な形でとても役にたっているのは、どんなプロジェクトでもその貢献者は自薦だということだ。初期にコメントをくれた人が指摘してくれたことだけれど、貢献は、ランダムなサンプルから出てくる訳じゃなくて、そのソフトを使うだけの興味を持って、その仕組みを学び、出くわした問題への解決を探そうとして、まあまともそうな解決策を作るだけのことをした人から寄せられる。これだけのフィルタを全部突破してくる人は、貢献できるだけのものは持っている可能性がかなり高い。

　Jeff Dutky @<code>{<dutky@wam.umd.edu>}は、リーヌスの法則は「デバッグは並列処理可能だ」と言い換えることもできると指摘してくれた。感謝したい。Jeffの知見では、デバッグするにはデバッガは開発コーディネータと多少のやりとりは必要だけれど、デバッガ同士では大した調整は必要ない。だから、開発者を加えることで発生する、幾何級数的な複雑性と管理コスト増大という問題には直面しないですむというわけだ。

　実際問題として、デバッガたちの作業重複によって生じる理論的な無駄は、Linuxの世界ではほとんど問題にされないようだ。「はやめしょっちゅうのリリース」の効果の一つとして、すでにフィードバック済みのバグフィックスをすばやく広めることでそういう重複をなくせるということがある@<fn>{JH}。

　ブルックスは、すでに Jeff の見解に関連したような観察をなにげなく述べてる。「広範に使われるプログラムをメンテナンスするコストは、おおむねその開発コストの 40％だ。驚いたことに、このコストはユーザ数に大きく左右される。@<strong>{ユーザが増えると見つかるバグも増える}のだ」（強調筆者）。

　ユーザが増えると見つかるバグも増えるのは、ユーザを追加することで、プログラムをもっといろんな方法で叩いてみることができるからだ。この効果は、そのユーザたちが共同開発者でもある場合にはさらに増幅される。各人が、ちょっとずつちがったものの見方と分析用ツールキットをもって、その任に当たる。「デルファイ効果」はまさにこの多様性のためにうまく機能するらしい。デバッグという分野に限った話をすると、この多様性のおかげで試みが重複する機会も減るらしい。

　だからベータテスタの数を増やしても、@<strong>{開発者側の}立場からすれば目下の「一番深い」バグの複雑さが減るわけではないけれど、でもだれかのツールキットがその問題にうまくマッチして、@<strong>{その人にとっては}そのバグが深刻ではないという可能性を増してくれるわけだ。

　リーヌスも、そこらへんは抜け目なくやってる。万が一@<strong>{本当に}深刻なバグがあったときのために、Linuxカーネルのバージョンのナンバリングには工夫がある。ユーザ候補は、「安定」とされたカーネル最新版を使うか、最先端にいって、新しい機能を使うかわりにバグの危険をおかすか、という選択ができるようになってる。この戦術は、ほかの Linuxハッカーたちはまだ正式に採用していないけれど、でも採用されるべきかもしれない。選択肢があるというのは、魅力を増すから。

//footnote[JH][　John Haslerは、ある作業が重複してやられたところで、オープンソースの開発にとっては差し引きであまり足をひっぱる結果にはならないと示唆してくれた。かれが提案したものを「ハスラーの法則」と呼ぼう。重複作業のコストは、そのチームのサイズの二乗より少ない――つまり、そういう重複を避けるために必要な、計画やマネジメントのオーバーヘッドに比べて増え方が遅いのだ。@<br>{}　この主張は、実はブルックスの法則に反するものではない。複雑なオーバーヘッド総額と、バグへの弱さがチームサイズの二乗に比例するのは事実かもしれないけれど、でも@<strong>{重複作業}からくるコストは、もっとゆっくりスケールする特殊な例でしかない。これにもっともらしい理由をつけるのは、そんなにむずかしくない。まずは、ほとんどのバグの原因となっている、計画外のよからぬ相互作用を防ぐのに比べれば、開発者のコード同士で機能の仕分けについて話あうのはずっと簡単だという、まちがいのない事実からも説明できる。@<br>{}　リーヌスの法則とハスラーの法則を組み合わせると、ソフトプロジェクトでサイズの段階が3段階くらいあることがわかる。小規模なプロジェクトでは（つまり開発者が一人からせいぜい三人くらいだろう）、リーダーとなるプログラマを選ぶ以外には、ややこしいマネジメント構造は必要ない。そしてそれを超えた中間くらいのところで、伝統的なマネジメントのコストがそこそこ低くて、作業の重複を避けたり、バグを追跡したり、細かい見落としがないかを調べるためのマネジメントがメリットをもたらすサイズがあるだろう。@<br>{}　でもそれを超えるとリーヌスの法則とハスラーの法則が組み合わさって、伝統的なマネジメントのコストと問題が、作業重複からの期待トラブルよりも急速に増えるサイズというのが出てくるだろう。このコストのなかでも無視できないのが、「目玉たくさん効果」を導入できないという構造的な問題だ。目玉が多いほうが（これまで見てきたように）伝統的なマネジメントよりも、バグの見落としや細部の見落としに対してはずっと効果的なのだ。だから大規模プロジェクトのケースでは、この 2 法則の組み合わせのおかげで伝統的なマネジメントのメリットは、ゼロにまで下がってしまう。]
